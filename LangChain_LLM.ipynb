{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5PmseQsMmdYY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8f3828e1-cb93-4ca7-d6cb-b329965a16c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install openai\n",
        "# !pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "tMzhJ24Jmi9i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/sample_data/OPENAI_API_KEY.txt\", \"r\")\n",
        "openai_api_key = f.read()\n",
        "# print(openai_api_key)\n",
        "client = openai.OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "en7RsF9Um2dE"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "_TyLogXKm8zS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_and_token_count(prompt,\n",
        "                                   model=llm_model,\n",
        "                                   temperature=0,\n",
        "                                   max_tokens=500):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt+' output in JSON format'}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,        # messages = [{\"role\": \"user\", \"content\": prompt}], a list of messages comprising the conversation so far.\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,    # The maximum number of tokens that can be 'generated' by the chat completion.\n",
        "    )\n",
        "\n",
        "    content = response.choices[0].message.content\n",
        "\n",
        "    token_dict = {\n",
        "        'prompt_tokens':response.usage.prompt_tokens, # no. of input tokens counted by OpenAI API\n",
        "        'completion_tokens':response.usage.completion_tokens,\n",
        "        'total_tokens':response.usage.total_tokens,\n",
        "    }\n",
        "    print(response)\n",
        "    print(content)\n",
        "    print(token_dict)\n",
        "\n",
        "    return response, content, token_dict"
      ],
      "metadata": {
        "id": "Zrd3QOE9nFNB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response, content, token_dict = get_completion_and_token_count(\"What is 1+1?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "G3Syhi2QnHxG",
        "outputId": "2f381f34-5466-4912-df98-90359715fa41"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-92alWLIj2RHWdi0LmTYY0NGzVA8aa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"result\": 2\\n}', role='assistant', function_call=None, tool_calls=None))], created=1710405010, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f0b692a78', usage=CompletionUsage(completion_tokens=9, prompt_tokens=18, total_tokens=27))\n",
            "{\n",
            "  \"result\": 2\n",
            "}\n",
            "{'prompt_tokens': 18, 'completion_tokens': 9, 'total_tokens': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "encoding.encode(\"What is 1+1?\") # no. of input tokens counted by OpenAI API"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pzzDaUaL3R-J",
        "outputId": "0fe0ddaf-ed22-40cb-e87e-e495dada7978"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3923, 374, 220, 16, 10, 16, 30]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Chat API : LangChain***"
      ],
      "metadata": {
        "id": "agJufpkQFo9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain"
      ],
      "metadata": {
        "id": "WGB0fXFH3E2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "V-gUvYYDv8P7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "M2EgnqTNFyBa"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key # MUST\n",
        "# To control the randomness and creativity of the generated text by an LLM, use temperature = 0.0\n",
        "chat = ChatOpenAI(temperature=0.0, model=llm_model)"
      ],
      "metadata": {
        "id": "v_p0WB9RF4Bc"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt template - Input into the model"
      ],
      "metadata": {
        "id": "tmLmTqPawAq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iClYMINJF6kt"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "9J1DzQIhHprv"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_template.messages[0].prompt)\n",
        "print(prompt_template.messages[0].prompt.input_variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sktdvD3gHsJK",
        "outputId": "e276e826-8906-4fa2-8556-ad6b28815b67"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['style', 'text'] template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n'\n",
            "['style', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "46wd30wrHvQC",
        "outputId": "e98f1b8a-1868-4156-d759-c37774ef832a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['style', 'text']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\"\n",
        "Hi how are you doing\n",
        "\"\"\"\n",
        "customer_style = \"\"\"Spanish \\\n",
        "in a calm and respectful tone\n",
        "\"\"\"\n",
        "customer_messages = prompt_template.format_messages(\n",
        "                    style=customer_style,\n",
        "                    text=customer_email)"
      ],
      "metadata": {
        "id": "zIheocqYHy9R"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(customer_messages))\n",
        "print(customer_messages)\n",
        "print(type(customer_messages[0]))\n",
        "print(customer_messages[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nx3RumyrIyYD",
        "outputId": "4c052b93-f0cc-4d2a-a548-b417f350f8b0"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "[HumanMessage(content='Translate the text that is delimited by triple backticks into a style that is Spanish in a calm and respectful tone\\n. text: ```\\nHi how are you doing\\n```\\n')]\n",
            "<class 'langchain_core.messages.human.HumanMessage'>\n",
            "content='Translate the text that is delimited by triple backticks into a style that is Spanish in a calm and respectful tone\\n. text: ```\\nHi how are you doing\\n```\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the LLM to translate to the style of the customer message\n",
        "customer_response = chat(customer_messages)"
      ],
      "metadata": {
        "id": "BOAGG3DNJEgr"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(customer_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zdZtpnVSJlQq",
        "outputId": "637fc9ce-9599-4312-e470-2aa3e94cb407"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola, ¿cómo estás?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse the LLM output string into a Python dictionary"
      ],
      "metadata": {
        "id": "sfD-LDiSwFec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser"
      ],
      "metadata": {
        "id": "oDioHb8mdu9w"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_body_schema = ResponseSchema(name=\"email_body\",\n",
        "                                      description=\"Extract email body\")\n",
        "\n",
        "email_from_schema = ResponseSchema(name=\"email_sender\",\n",
        "                                      description=\"Extract sender email\")\n",
        "\n",
        "email_from_name_schema = ResponseSchema(name=\"email_sender_name\",\n",
        "                                      description=\"Extract sender name\")\n",
        "\n",
        "email_from_designation_schema = ResponseSchema(name=\"email_sender_designation\",\n",
        "                                      description=\"Extract sender designation\")\n",
        "\n",
        "email_from_organization_schema = ResponseSchema(name=\"email_sender_organization\",\n",
        "                                      description=\"Extract sender orgaization\")\n",
        "\n",
        "email_date_schema = ResponseSchema(name=\"email_date\",\n",
        "                                       description=\"Extract email date\")\n",
        "\n",
        "email_to_schema = ResponseSchema(name=\"email_recipients\",\n",
        "                                      description=\"Extract comma separated email recipients\")\n",
        "\n",
        "response_schemas = [email_from_schema,\n",
        "                    email_from_name_schema,\n",
        "                    email_from_designation_schema,\n",
        "                    email_from_organization_schema,\n",
        "                    email_to_schema,\n",
        "                    email_date_schema,\n",
        "                    email_body_schema]"
      ],
      "metadata": {
        "id": "3eoyTsEiepwM"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ],
      "metadata": {
        "id": "6d5gBog4fwpx"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3jZZwxLf0Gk",
        "outputId": "1653f825-2aa6-4af3-d22f-0c946ad4aab1"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"email_sender\": string  // Extract sender email\n",
            "\t\"email_sender_name\": string  // Extract sender name\n",
            "\t\"email_sender_designation\": string  // Extract sender designation\n",
            "\t\"email_sender_organization\": string  // Extract sender orgaization\n",
            "\t\"email_recipients\": string  // Extract comma separated email recipients\n",
            "\t\"email_date\": string  // Extract email date\n",
            "\t\"email_body\": string  // Extract email body\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email = \"From: Doe, John <JohnDoe@xyz.com> \\\n",
        "Sent: Wednesday, March 15, 2023 11:21 PM \\\n",
        "To: Hollester, Mike <@MHollester.com>; Parrera, Nicky <NParrera@xyz.com> \\\n",
        "Cc: Bush, Johnny <JBush@xyz.com>; Herding, Bill <BHerding@xyz.com> \\\n",
        "Subject: RE: Interested in AI product  \\\n",
        "I hope this email finds you well. \\\n",
        "I am reaching out to inquire about your company's AI offerings and services. \\\n",
        "Could you please provide more information regarding your capabilities and solutions in this field? \\\n",
        "Shawn Ponting \\\n",
        "Senior Product Manager \\\n",
        "Great Corporation\""
      ],
      "metadata": {
        "id": "kJJ49a-cikiu"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_template_2 = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "email_body: Extract email body If this information is not found,output Unknown Email Body\n",
        "email_sender: Extract sender email If this information is not found, output Unknown Sender.\n",
        "email_sender_designation: Extract sender designation If this information is not found, output Unknown Sender Designation.\n",
        "email_sender_organization: Extract sender organization If this information is not found, output Unknown Sender Organization.\n",
        "email_date: Extract email date If this information is not found, output Unknown Date.\n",
        "email_recipients: Extract comma separated email recipients If this information is not found, output Unknown Recipients.\n",
        "\n",
        "text: {text}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rw_oJbLMhccE"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
        "\n",
        "messages = prompt.format_messages(text=email,\n",
        "                                format_instructions=format_instructions)"
      ],
      "metadata": {
        "id": "YsqGWylnf9ao"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(messages[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeuIWYHgjCaU",
        "outputId": "1fe55f2d-da64-4e7e-9f75-2a05b17a0dad"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the following text, extract the following information:\n",
            "\n",
            "email_body: Extract email body If this information is not found,output Unknown Email Body \n",
            "email_sender: Extract sender email If this information is not found, output Unknown Sender.\n",
            "email_sender_designation: Extract sender designation If this information is not found, output Unknown Sender Designation.\n",
            "email_sender_organization: Extract sender organization If this information is not found, output Unknown Sender Organization.\n",
            "email_date: Extract email date If this information is not found, output Unknown Date.\n",
            "email_recipients: Extract comma separated email recipients If this information is not found, output Unknown Recipients.\n",
            "\n",
            "text: From: Doe, John <JohnDoe@xyz.com> Sent: Wednesday, March 15, 2023 11:21 PM To: Hollester, Mike <@MHollester.com>; Parrera, Nicky <NParrera@xyz.com> Cc: Bush, Johnny <JBush@xyz.com>; Herding, Bill <BHerding@xyz.com> Subject: RE: Interested in AI product  I hope this email finds you well. I am reaching out to inquire about your company's AI offerings and services. Could you please provide more information regarding your capabilities and solutions in this field? Shawn Ponting Senior Product Manager Great Corporation\n",
            "\n",
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"email_sender\": string  // Extract sender email\n",
            "\t\"email_sender_name\": string  // Extract sender name\n",
            "\t\"email_sender_designation\": string  // Extract sender designation\n",
            "\t\"email_sender_organization\": string  // Extract sender orgaization\n",
            "\t\"email_recipients\": string  // Extract comma separated email recipients\n",
            "\t\"email_date\": string  // Extract email date\n",
            "\t\"email_body\": string  // Extract email body\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat(messages)"
      ],
      "metadata": {
        "id": "O5ai56sajIRp"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rESZeTFjKf-",
        "outputId": "60d59cc4-bed7-4584-fd08-7b2d8076dd46"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "\t\"email_sender\": \"JohnDoe@xyz.com\",\n",
            "\t\"email_sender_name\": \"Doe, John\",\n",
            "\t\"email_sender_designation\": \"Senior Product Manager\",\n",
            "\t\"email_sender_organization\": \"Great Corporation\",\n",
            "\t\"email_recipients\": \"Hollester, Mike <@MHollester.com>, Parrera, Nicky <NParrera@xyz.com>, Bush, Johnny <JBush@xyz.com>, Herding, Bill <BHerding@xyz.com>\",\n",
            "\t\"email_date\": \"Wednesday, March 15, 2023 11:21 PM\",\n",
            "\t\"email_body\": \"I hope this email finds you well. I am reaching out to inquire about your company's AI offerings and services. Could you please provide more information regarding your capabilities and solutions in this field?\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict = output_parser.parse(response.content)"
      ],
      "metadata": {
        "id": "VpYBofoBjNlk"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ypJqzq1jPAn",
        "outputId": "be443cc4-9c7f-4ffa-9918-554a8c45ff43"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'email_sender': 'JohnDoe@xyz.com',\n",
              " 'email_sender_name': 'Doe, John',\n",
              " 'email_sender_designation': 'Senior Product Manager',\n",
              " 'email_sender_organization': 'Great Corporation',\n",
              " 'email_recipients': 'Hollester, Mike <@MHollester.com>, Parrera, Nicky <NParrera@xyz.com>, Bush, Johnny <JBush@xyz.com>, Herding, Bill <BHerding@xyz.com>',\n",
              " 'email_date': 'Wednesday, March 15, 2023 11:21 PM',\n",
              " 'email_body': \"I hope this email finds you well. I am reaching out to inquire about your company's AI offerings and services. Could you please provide more information regarding your capabilities and solutions in this field?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "glkloAdBqxmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}